---
title: "reporteBayes"
author: "Flavio Galán, José Prince"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)

load_data <- function(){
  training_data <- read.csv("data/train.csv")
  test_data <- read.csv("data/test.csv")
}

training_data <- read.csv("data/train.csv")
training_data_sorted <- training_data[order(training_data$SalePrice, decreasing = TRUE),]
```

[Link al Repositorio](https://github.com/ElrohirGT/Proyecto2_MineriaDeDatos)

# Modelado de Bayes

Debido al modelado de Bayes tenemos que discretizar la variable objetivo, en nuestro caso es SalePrice. La vamos a dividir en 4 categorìas: LOW, SEMI, MEDIUM, HIGH

Primero vamos a dividir el dataset the entrenamiento en 2 grupos, uno de entrenamiento con el 70% de los datos y otro de validación con el 30% de los datos. 

```{r Naïve Bayes}
library(e1071)  # For Naïve Bayes
library(dplyr)
library(caret)  # For data splitting
library(glmnet)

load_data()

# Define price categories (Low, Medium, High) using quantiles
training_data$SalePriceCategory <- cut(training_data$SalePrice, 
                            breaks = quantile(training_data$SalePrice, probs = c(0, 0.33, 0.66, 1), na.rm = TRUE), 
                            labels = c("Barata", "Media", "Cara"), 
                            include.lowest = TRUE)

df <- training_data %>% select(-SalePrice, -Id)  # Remove ID and continuous SalePrice

df <- df %>% mutate_if(is.character, as.factor)

set.seed(42)
train_index <- createDataPartition(training_data$SalePriceCategory, p = 0.7, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]

nb_model <- naiveBayes(SalePriceCategory ~ ., data = train_data)

predictions <- predict(nb_model, test_data)

conf_matrix <- confusionMatrix(predictions, test_data$SalePriceCategory)
print(conf_matrix)
```

Para predecir la variable de SalePrice el modelo tuvo un _Accuracy_ del 70%, lo que significa que sí ha encontrado patrones que implican un valor de venta mayor/menor. Comparando este modelo con los otros realizados con anterioridad el que mejor lo ha realizado hasta ahora es el de naïve Bayes aunque por muy poco, puesto que apenas superó por 1% al modelo de árboles de regresión.

Como se puede ver por la matriz de confusión la clase en la que más errores tuvo fue la clase barata, puesto que de todos los valores clasificados en "Barato" solamente el 65% fueron clasificados de forma correcta. La segunda categoría con más errores fue la media con el 67% clasificados de forma correcta y finalmente la Cara con 80%.

Es posible que esto se deba a los puntos atípicos del dataset se parte del precio de las casas, por lo que si quitamos las 2 casas con precio mayor tenemos:

```{r Naïve Bayes - Sin puntos atípicos}
library(e1071)  # For Naïve Bayes
library(dplyr)
library(caret)  # For data splitting

library(ggplot2)

load_data()

mean_price <- mean(training_data$SalePrice, na.rm = TRUE)
sd_price <- sd(training_data$SalePrice, na.rm = TRUE)

upper_limit <- mean_price + (4 * sd_price)

ggplot(training_data, aes(x = SalePrice)) +
  geom_histogram(aes(y = ..density..), binwidth = 10000, fill = "blue", color = "black", alpha = 0.7) +
  geom_density(color = "red", size = 1.2) +
  geom_vline(xintercept = upper_limit, color = "purple")+
  geom_vline(xintercept = mean(training_data$SalePrice), color = "green")+
  theme_minimal() +
  labs(title = "Distribution of House Sale Prices with Density Curve",
       x = "Sale Price",
       y = "Density") +
  theme(plot.title = element_text(hjust = 0.5))

filtered_training_data <- training_data %>% filter(SalePrice <= upper_limit)

# Define price categories (Low, Medium, High) using quantiles
filtered_training_data$SalePriceCategory <- cut(filtered_training_data$SalePrice, 
                            breaks = quantile(filtered_training_data$SalePrice, probs = c(0, 0.33, 0.66, 1), na.rm = TRUE), 
                            labels = c("Barata", "Media", "Cara"),
                            include.lowest = TRUE)

df <- filtered_training_data %>% select(-SalePrice, -Id)  # Remove ID and continuous SalePrice

df <- df %>% mutate_if(is.character, as.factor)

set.seed(42)
train_index <- createDataPartition(filtered_training_data$SalePriceCategory, p = 0.7, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]

nb_model <- naiveBayes(SalePriceCategory ~ ., data = filtered_training_data)

predictions <- predict(nb_model, test_data)

conf_matrix <- confusionMatrix(predictions, test_data$SalePriceCategory)
print(conf_matrix)
```

Después de probar varias iteraciones se obtuvo la mejor cantidad de resultados removiendo los puntos atípicos, en donde atípicos significa "Tienen un precio mayor a la media + 4 veces la desviación estándar". Como se puede ver el _Accuracy_ del modelo tuvo una ligera mejora (ascendió a 73%) y la eficiencia del modelo también aumentó levemente como se ve por la matriz de confusión.

Viendo los resultados de la matriz de confusión y las métricas de precisión, se puede notar que tiene sobreajuste. Este modelo clasifica con una sensibilidad del 96.46% y 82.16% a las casas Baratas y Caras respectivamente. Sin embargo, la clasificación de las casas Medias es del 39.88%, lo que sugiere que el modelo ha aprendido demasiado los patrones de cuertas clases y no generaliza bien. 

```{r NV Cross Validation}
# 
tu_datos <- df %>% mutate_if(is.character, as.factor)
X <- tu_datos[, -which(names(tu_datos) == "SalePriceCategory")]
y <- tu_datos$SalePriceCategory

train_control <- trainControl(method = "cv", number = 10)
modelo_nb_cv <- suppressWarnings(train(x = X, y = y, method = "naive_bayes", trControl = train_control))

predicciones <- suppressWarnings(predict(modelo_nb_cv, newdata = test_data))
suppressWarnings(confusionMatrix(predicciones, test_data$SalePriceCategory))
```

Con este nuevo modelo generado mediante validación cruzada podemos ver una mejora en la _Accuracy_ del modelo. Ahora vemos que el modelo tiene un porcentaje de accuracy del 77% siendo mayor que los modelos anteriores de Naive Bayes.

Ahora evaluaremos con diferentes hiperparámetros los modelos de clasificación y regresión.

```{r Hiperparámetros}

library(DMwR2)  # Para la imputación de valores faltantes

filtered_training_data <- centralImputation(filtered_training_data)
# Definir la cuadrícula de hiperparámetros para el ajuste
tune_grid <- expand.grid(laplace = c(0, 0.5, 1, 2),
                        usekernel = c(TRUE, FALSE),
                        adjust = c(1, 1.5, 2))

# Aplicar ajuste de hiperparámetros usando el método de validación cruzada
train_control <- trainControl(method = "cv", number = 10)

# Ajuste del modelo de Naive Bayes
modelo_nb_tune <- train(SalePriceCategory ~ ., data = filtered_training_data, 
                        method = "naive_bayes", 
                        trControl = train_control, 
                        tuneGrid = tune_grid)

# Usar el mejor modelo del ajuste para hacer predicciones
best_model <- modelo_nb_tune$finalModel
predictions <- predict(best_model, newdata = test_data)

# Evaluar el rendimiento del modelo ajustado
conf_matrix <- confusionMatrix(predictions, test_data$SalePriceCategory)
print(conf_matrix)

```

El modelo de Naive Bayes no mejoró significativamente debido a varios fcatores. La matriz de confusión muestra que el modelo tiene un buen desempeño al clasificar casas baratas pero tiene dificultades para las "Medias" y "Caras". Esto se debe al desbalanceo en la distribución de clases, favoreciendo las clases más comunes. El desempeño general del modelo, con precisión del 63%, está afectado por la suposición de independencia de caracterpisticas que Naive Bayes hace, ya que puede haber interacciones entre las caracteristicas que el modelo no está capturando.

Viendo el _Accuracy_ del árbol de decisión y el random forest, se obtuvo que su accuracy era de 90% y 91%. Esto contrasta con lo obtenido con Naive Bayes viendo que su capacidad de predicción es peor que la de un random forest. Incluso viendo el tiempo de ejecución, se ve que el random forest se tarda menos en procesar, teniendo actualmente una diferencia de procesamiento de 5s aproximadamente.
---
title: "ReporteArboles"
author: "Flavio Galán, José Prince"
date: "`r Sys.Date()`"
output: html_document
---

Link del repositorio: https://github.com/ElrohirGT/Proyecto2_MineriaDeDatos

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(class)
library(caret)
library(dplyr)
library(Metrics)

normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }

# Cargar datos
training_data <- read.csv("data/train.csv")

# Reemplazar valores NA con 0
training_data[is.na(training_data)] <- 0

training_data <- training_data[-1]
# Seleccionar solo columnas numéricas
training_data_numeric <- training_data %>% select_if(is.numeric)

# Definir variables predictoras y respuesta
predictors <- training_data_numeric %>% select(-SalePrice)

response <- training_data_numeric$SalePrice

# Normalización (Estandarización Z-score)
preProc <- preProcess(predictors, method = c("center", "scale"))
predictors_scaled <- predict(preProc, predictors)

# Semilla para reproducibilidad
set.seed(123)

# Separar datos en entrenamiento (70%) y prueba (30%)
train_indices <- createDataPartition(response, p = 0.7, list = FALSE)

train_data <- predictors_scaled[train_indices, ]
train_labels <- response[train_indices]

test_data <- predictors_scaled[-train_indices, ]
test_labels <- response[-train_indices]

```

# Modelo de regresión de KNN
Elaboración del modelo de regresión usando K nearest Neighbors:

```{r KNN model}
k <- round(sqrt(nrow(train_data)),0)

train_labels <- as.factor(train_labels)

knn_predictions <- knn(train = train_data,
                       test = test_data,
                       cl = train_labels,
                       k = k)

knn_predictions <- as.numeric(as.character(knn_predictions))

results <- data.frame(Real = test_labels, Predicho = knn_predictions)
head(results)
```

Podemos ver que en la tabla anterior se hace una comparación entre los datos predichos por el modelo y los datos reales. Para los datos predichos se puede ver que los datos tienen un desfase del 16% para la predicción del dato real. 

Ahora analizaremos las métricas del modelo para conocer que tan bueno es el modelo. 

```{r R2}
mse_value <- mse(test_labels, knn_predictions)
rmse_value <- rmse(test_labels, knn_predictions)
mae_value <- mae(test_labels, knn_predictions)
r2_value <- 1 - (sum((knn_predictions - test_labels)^2) / sum((test_labels - mean(test_labels))^2))

cat("MSE:", mse_value, "\n")
cat("RMSE:", rmse_value, "\n")
cat("MAE:", mae_value, "\n")
cat("R²:", round(r2_value * 100, 2), "%\n")
```

Analizando las métricas obtenicas vemos los siguientes indicios. Analizando el RMSE, proveniente del MSE, vemos que hay grandes diferencias entre las predicciones y los valores reales; el modelo se equivoca en aproximadamente $63,199.32. Ahora analizando el MAE obtenemos un error promedio de $41,029.34, lo que indica que las predicciones estan desviadas por este monto (en promedio). Por último, el R^2 de 34.23% indica que solo el 34.23% de la variabilidad en los precios de las casas se explica con la variable SalePrice; este valor tan bajo demuestra que el modelo no está captando bien los patrones en los datos y que hay un 66% de la variabilidad que el modelo no explica.

# Modelos de regresión

Para analizar los diferentes modelos de regresión vamos a comparar el R^2 a través de los R^2 que se ha calculado para cada uno de estos modelos.

| Modelo                       | R^2 (%)     |
|------------------------------|-------------|
| Modelo de regresión lineal   | 69.97       |
| Modelo de árbol de regresión | 76.54       |
| Modelo de naive bayes        | 70.71       |
| Modelo de KNN                | 58.53       |

Se puede ver que el modelo que funcionó mejor fue el de árbol de regresión y el modelo que tuvo peor rendimiento fue el de KNN.

# Modelo KNN de clasificación

```{r Clasification Model}

# Calcular media y desviación estándar
mean_price <- mean(training_data$SalePrice, na.rm = TRUE)
sd_price <- sd(training_data$SalePrice, na.rm = TRUE)

# Definir umbrales
lower_threshold <- mean_price - 1.5 * sd_price
upper_threshold <- mean_price + 1.5 * sd_price

# Asignar categorías correctamente
training_data$SalePriceCategory <- case_when(
  training_data$SalePrice < lower_threshold ~ "Barata",
  training_data$SalePrice > upper_threshold ~ "Cara",
  TRUE ~ "Mediana"
)

# Convertir en factor
training_data$SalePriceCategory <- factor(training_data$SalePriceCategory)

# Ver distribución de las categorías
table(training_data$SalePriceCategory)

# Partición de datos con la columna correcta
set.seed(123)
train_indices <- createDataPartition(training_data$SalePriceCategory, p = 0.7, list = FALSE)

train_data <- training_data[train_indices, ]
test_data <- training_data[-train_indices, ]

# Normalizar solo variables numéricas
train_data_numeric <- as.data.frame(lapply(train_data %>% select_if(is.numeric), normalize))
test_data_numeric <- as.data.frame(lapply(test_data %>% select_if(is.numeric), normalize))

# Definir variables predictoras y respuesta
train_labels <- train_data$SalePriceCategory
test_labels <- test_data$SalePriceCategory

# Definir número óptimo de vecinos
k <- round(sqrt(nrow(train_data)), 0)

# Aplicar KNN
knn_predictions <- knn(train = train_data_numeric,
                       test = test_data_numeric,
                       cl = train_labels,
                       k = k)

```

El modelo de clasificación se realizó en base a estos parámetros:

* Baratas: Todas las casas menores a media - 1.5 desviaciones estándar en valor.
* Medianas: Todas las casas entre media+- 1.5 desviaciones estándar en valor.
* Caras: Todas las casas mayores a media + 1.5 desviaciones estándar en valor.

```{r Confusion Matrix}
# Matriz de confusión
conf_matrix <- confusionMatrix(knn_predictions, test_labels)
print(conf_matrix)
```

El análisis de la matriz de confusión muestra que el modelo tiene un alto accuracy (94.74%), lo que indica que, en general, el clasificador está funcionando bien, pero presenta una fuerte desbalance entre las clases. Para la clase "Barata", la sensibilidad es 0, lo que significa que el modelo no ha identificado ninguna casa como "Barata". Esto es un indicio de que hay muy pocos ejemplos de esta clase en los datos y el modelo no logra capturarlos correctamente. En cuanto a la clase "Cara", la sensibilidad es bastante baja (0.44), pero tiene un valor perfecto en la especificidad (1), lo que sugiere que cuando el modelo predice "Cara", es casi siempre correcta. Para la clase "Mediana", el modelo muestra una excelente sensibilidad (1), lo que significa que identifica correctamente casi todas las casas medianas. Sin embargo, su especificidad es baja (0.39), lo que indica que las casas que no son medianas tienden a ser clasificadas erróneamente como medianas.

No consideramos que el modelo esté sobreajustado principalmente porque hay dos clases enteras en las cuales su especificidad es muy baja, lo que significa que hay varios valores que todavía clasifica erróneamente, si el modelo estuviera sobreajustado, esto no ocurriría.


# Entrenamiento usando validación cruzada
```{r}
# Cargar librerías necesarias
library(caret)

# Definir control de validación cruzada (10-fold)
train_control <- trainControl(method = "cv", number = 10)

# Definir número óptimo de vecinos con búsqueda en grid
k_values <- round(sqrt(nrow(train_data)), 0)

# Entrenar modelo KNN con validación cruzada
knn_model <- train(SalePriceCategory ~ ., 
                   data = cbind(train_data_numeric, SalePriceCategory = train_labels), 
                   method = "knn", 
                   trControl = train_control,
                   tuneGrid = expand.grid(k = k_values))

# Ver resultados del modelo
print(knn_model)

# Hacer predicciones en test_data
test_predictions <- predict(knn_model, newdata = test_data_numeric)

# Evaluar el rendimiento del modelo
conf_matrix <- confusionMatrix(test_predictions, test_labels)
print(conf_matrix)
```

En nuestro caso, ya sea que lo entrenáramos de forma cruzada o no, realmente no hizo una diferencia significativa en los resultados, ambos modelos tienen matrices de confusión prácticamente idénticas.

# Tuneo de los modelos

En el KNN el único hiperparámetro que podemos modificar es justamente la K, es decir, cuántos vecinos vamos a tomar en cuenta.
```{r}

models <- function(k_value) {
  # Cargar librerías necesarias
library(caret)

# Definir control de validación cruzada (10-fold)
train_control <- trainControl(method = "cv", number = 10)

# Definir número óptimo de vecinos con búsqueda en grid
k_values <- round(sqrt(nrow(train_data)), 0)

# Entrenar modelo KNN con validación cruzada
knn_model <- train(SalePriceCategory ~ ., 
                   data = cbind(train_data_numeric, SalePriceCategory = train_labels), 
                   method = "knn", 
                   trControl = train_control,
                   tuneGrid = expand.grid(k = k_value))

print(paste("Modelo con K=", k_value))

# Ver resultados del modelo
print(knn_model)

# Hacer predicciones en test_data
test_predictions <- predict(knn_model, newdata = test_data_numeric)

# Evaluar el rendimiento del modelo
conf_matrix <- confusionMatrix(test_predictions, test_labels)
print(conf_matrix)
}


models(1)
models(10)
models(20)
models(round(sqrt(nrow(train_data)), 0))
models(40)
```

De los modelos explorados, el que mejor matriz de confusión sigue teniendo fue el que utilizamos anteriormente, K=32 parece ser justamente el mejor sweet spot, la lógica utilizada fue obtener la raíz cuadrada de la cantidad de filas.

# Conclusiones Finales

Comparando el modelo obtenido con KNN con respecto a los anteriores se ve un claro aumento en precisión, nuestro modelo KNN tuvo la mayor precisión con 94% seguido de los árboles de decisión en 91% y 90% y por último el naive bayes que resultó ser el peor con un 78%. Incluso en tiempos de procesamiento, el naive bayes ha sido el que más se ha tardado hasta ahora, posiblemente por nuestra implementación en R, talvez no usamos las librerías correctas, pero se tardó 5s más en promedio.

Debido a todo lo anterior, nuestra recomendación final es utilizar el modelo de KNN generado con K=32, esta configuración nos ha brindado los mejores resultados combinado también con una performance de entrenamiento decente.